{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for tensiometry of pendant drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages and self-defined classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F  # useful stateless functions\n",
    "#Test/Train data split\n",
    "from functools import lru_cache\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import logging\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# os\n",
    "import os\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# self-defined model\n",
    "from model_pic import *\n",
    "from model_cal import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSplit:\n",
    "\n",
    "    def __init__(self, dataset, test_train_split=0.8, val_train_split=0.1, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "\n",
    "        dataset_size = len(dataset)\n",
    "        self.indices = list(range(dataset_size))\n",
    "        test_split = int(np.floor(test_train_split * dataset_size))\n",
    "\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "        train_indices, self.test_indices = self.indices[:test_split], self.indices[test_split:]\n",
    "        train_size = len(train_indices)\n",
    "        validation_split = int(np.floor((1 - val_train_split) * train_size))\n",
    "\n",
    "        self.train_indices, self.val_indices = train_indices[:validation_split], train_indices[validation_split:]\n",
    "\n",
    "        self.train_sampler = SubsetRandomSampler(self.train_indices)\n",
    "        self.val_sampler = SubsetRandomSampler(self.val_indices)\n",
    "        self.test_sampler = SubsetRandomSampler(self.test_indices)\n",
    "    \n",
    "    def get_train_split_point(self):\n",
    "        return len(self.train_sampler) + len(self.val_indices)\n",
    "\n",
    "    def get_validation_split_point(self):\n",
    "        return len(self.train_sampler)\n",
    "\n",
    "    @lru_cache(maxsize=4)\n",
    "    def get_split(self, batch_size=50, num_workers=4):\n",
    "        logging.debug('Initializing train-validation-test dataloaders')\n",
    "        self.train_loader = self.get_train_loader(batch_size=batch_size, num_workers=num_workers)\n",
    "        self.val_loader = self.get_validation_loader(batch_size=batch_size, num_workers=num_workers)\n",
    "        self.test_loader = self.get_test_loader(batch_size=batch_size, num_workers=num_workers)\n",
    "        return self.train_loader, self.val_loader, self.test_loader\n",
    "\n",
    "    @lru_cache(maxsize=4)\n",
    "    def get_train_loader(self, batch_size=50, num_workers=4):\n",
    "        logging.debug('Initializing train dataloader')\n",
    "        self.train_loader = DataLoader(self.dataset, batch_size=batch_size, sampler=self.train_sampler, shuffle=False, num_workers=num_workers)\n",
    "        return self.train_loader\n",
    "\n",
    "    @lru_cache(maxsize=4)\n",
    "    def get_validation_loader(self, batch_size=50, num_workers=4):\n",
    "        logging.debug('Initializing validation dataloader')\n",
    "        self.val_loader = DataLoader(self.dataset, batch_size=batch_size, sampler=self.val_sampler, shuffle=False, num_workers=num_workers)\n",
    "        return self.val_loader\n",
    "\n",
    "    @lru_cache(maxsize=4)\n",
    "    def get_test_loader(self, batch_size=50, num_workers=4):\n",
    "        logging.debug('Initializing test dataloader')\n",
    "        self.test_loader = DataLoader(self.dataset, batch_size=batch_size, sampler=self.test_sampler, shuffle=False, num_workers=num_workers)\n",
    "        return self.test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8220, 165)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "165",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/pandas/core/indexes/base.py?line=3619'>3620</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2131\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2140\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 165",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jrimm\\Documents\\tue\\DL_Pendant_Drop_Tensiometry\\main.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jrimm/Documents/tue/DL_Pendant_Drop_Tensiometry/main.ipynb#ch0000004?line=9'>10</a>\u001b[0m data_matrix \u001b[39m=\u001b[39m data_matrix\u001b[39m.\u001b[39mappend(d, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jrimm/Documents/tue/DL_Pendant_Drop_Tensiometry/main.ipynb#ch0000004?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(data_matrix\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jrimm/Documents/tue/DL_Pendant_Drop_Tensiometry/main.ipynb#ch0000004?line=11'>12</a>\u001b[0m data_matrix \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(data_matrix)\n",
      "File \u001b[1;32mc:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/pandas/core/frame.py?line=3502'>3503</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/pandas/core/frame.py?line=3503'>3504</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/pandas/core/frame.py?line=3504'>3505</a>\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/pandas/core/frame.py?line=3505'>3506</a>\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/pandas/core/frame.py?line=3506'>3507</a>\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/pandas/core/indexes/base.py?line=3622'>3623</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/pandas/core/indexes/base.py?line=3623'>3624</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/pandas/core/indexes/base.py?line=3624'>3625</a>\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/pandas/core/indexes/base.py?line=3625'>3626</a>\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/pandas/core/indexes/base.py?line=3626'>3627</a>\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/pandas/core/indexes/base.py?line=3627'>3628</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 165"
     ]
    }
   ],
   "source": [
    "data_matrix = df = pd.DataFrame()\n",
    "Data_point = \"Data\"\n",
    "d = pd.read_csv(\"Data_folder/\" + str(Data_point) + \".csv\", header=None)\n",
    "\n",
    "st = d[0]\n",
    "volume0 = d[1]\n",
    "rneedle = d[2]\n",
    "rr_zz = d.loc[0][3:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deside to apply host or device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the functions we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_cal_per_epoch(loss_list, model, loader) -> list:\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        loss_epoch = 0\n",
    "        for _, data in enumerate(train_loader):\n",
    "            x = data[:, 3:].to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "            y = data[:, 0].to(device=device, dtype=torch.float32)\n",
    "            scores = model(x)\n",
    "            loss = F.mse_loss(scores, y)\n",
    "            loss_epoch += loss\n",
    "        loss_list.append(loss_epoch/t)\n",
    "\n",
    "def train(model, optimizer, epochs=1):\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for _, data in enumerate(train_loader):\n",
    "            model.train()  # put model to training mode\n",
    "            x = data[:, 3:].to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "            y = data[:, 0].to(device=device, dtype=torch.float32)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.mse_loss(scores, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        loss_cal_per_epoch(loss_train, model, train_loader)\n",
    "        loss_cal_per_epoch(loss_val, model, val_loader)\n",
    "        print('epoch %d: train_loss = %.4f, val_loss = %.4f' % (e+1, loss_train[e], loss_val[e]))\n",
    "    \n",
    "    x = range(1, epochs+1)\n",
    "    plt.plot(x, loss_train, 'b-', label=\"training loss\")\n",
    "    plt.plot(x, loss_val, 'r--', label=\"validation loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"MSE Loss\")\n",
    "    plt.title(\"Train/Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def prediction(model, x):   # only a batch\n",
    "    model = model.to(device=device)\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        x = x.to(device=device, dtype=torch.float32)\n",
    "        score = torch.Tensor.cpu(model(x))\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train PhysicsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas\\_libs\\index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 2131, in pandas._libs.hashtable.Int64HashTable.get_item\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 2140, in pandas._libs.hashtable.Int64HashTable.get_item\nKeyError: 892\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\frame.py\", line 3505, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"c:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 892\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jrimm\\Documents\\tue\\DL_Pendant_Drop_Tensiometry\\main.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jrimm/Documents/tue/DL_Pendant_Drop_Tensiometry/main.ipynb#ch0000011?line=10'>11</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model_physics\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jrimm/Documents/tue/DL_Pendant_Drop_Tensiometry/main.ipynb#ch0000011?line=11'>12</a>\u001b[0m epoch \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jrimm/Documents/tue/DL_Pendant_Drop_Tensiometry/main.ipynb#ch0000011?line=13'>14</a>\u001b[0m train(model_physics, optimizer, epoch)\n",
      "\u001b[1;32mc:\\Users\\jrimm\\Documents\\tue\\DL_Pendant_Drop_Tensiometry\\main.ipynb Cell 10'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, epochs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jrimm/Documents/tue/DL_Pendant_Drop_Tensiometry/main.ipynb#ch0000009?line=15'>16</a>\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice)  \u001b[39m# move the model parameters to CPU/GPU\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jrimm/Documents/tue/DL_Pendant_Drop_Tensiometry/main.ipynb#ch0000009?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jrimm/Documents/tue/DL_Pendant_Drop_Tensiometry/main.ipynb#ch0000009?line=17'>18</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _, (data, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jrimm/Documents/tue/DL_Pendant_Drop_Tensiometry/main.ipynb#ch0000009?line=18'>19</a>\u001b[0m         model\u001b[39m.\u001b[39mtrain()  \u001b[39m# put model to training mode\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jrimm/Documents/tue/DL_Pendant_Drop_Tensiometry/main.ipynb#ch0000009?line=19'>20</a>\u001b[0m         x \u001b[39m=\u001b[39m data[:, \u001b[39m3\u001b[39m:]\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)  \u001b[39m# move to device, e.g. GPU\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1224\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/utils/data/dataloader.py?line=1221'>1222</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/utils/data/dataloader.py?line=1222'>1223</a>\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/utils/data/dataloader.py?line=1223'>1224</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[1;32mc:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1250\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/utils/data/dataloader.py?line=1247'>1248</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[0;32m   <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/utils/data/dataloader.py?line=1248'>1249</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/utils/data/dataloader.py?line=1249'>1250</a>\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[0;32m   <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/utils/data/dataloader.py?line=1250'>1251</a>\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\_utils.py:457\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/_utils.py?line=452'>453</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/_utils.py?line=453'>454</a>\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/_utils.py?line=454'>455</a>\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/_utils.py?line=455'>456</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Users/jrimm/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/_utils.py?line=456'>457</a>\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[1;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas\\_libs\\index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 2131, in pandas._libs.hashtable.Int64HashTable.get_item\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 2140, in pandas._libs.hashtable.Int64HashTable.get_item\nKeyError: 892\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\frame.py\", line 3505, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"c:\\Users\\jrimm\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 892\n"
     ]
    }
   ],
   "source": [
    "in_channel = 162\n",
    "node_1 = 1024\n",
    "node_2 = 1024\n",
    "node_3 = 512\n",
    "node_4 = 64\n",
    "num_classes = 1\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model_physics = PhysicsNet(in_channel, node_1, node_2, node_3, node_4, num_classes)\n",
    "optimizer = optim.Adam(model_physics.parameters(), lr=learning_rate)\n",
    "epoch = 10\n",
    "\n",
    "train(model_physics, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64def4006c78149665c79cf5850ee76c9e416630a0d9e75e41ff194dcaf5fb2b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
