{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for tensiometry of pendant drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages and self-defined classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F  # useful stateless functions\n",
    "#Test/Train data split\n",
    "from functools import lru_cache\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import logging\n",
    "# sklearn\n",
    "from sklearn import preprocessing\n",
    "# os\n",
    "import os\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# self-defined model\n",
    "from model_pic import *\n",
    "from model_cal import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSplit:\n",
    "\n",
    "    def __init__(self, dataset, test_train_split=0.8, val_train_split=0.1, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "\n",
    "        dataset_size = len(dataset)\n",
    "        self.indices = list(range(dataset_size))\n",
    "        test_split = int(np.floor(test_train_split * dataset_size))\n",
    "\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "        train_indices, self.test_indices = self.indices[:test_split], self.indices[test_split:]\n",
    "        train_size = len(train_indices)\n",
    "        validation_split = int(np.floor((1 - val_train_split) * train_size))\n",
    "\n",
    "        self.train_indices, self.val_indices = train_indices[:validation_split], train_indices[validation_split:]\n",
    "\n",
    "        self.train_sampler = SubsetRandomSampler(self.train_indices)\n",
    "        self.val_sampler = SubsetRandomSampler(self.val_indices)\n",
    "        self.test_sampler = SubsetRandomSampler(self.test_indices)\n",
    "    \n",
    "    def get_train_split_point(self):\n",
    "        return len(self.train_sampler) + len(self.val_indices)\n",
    "\n",
    "    def get_validation_split_point(self):\n",
    "        return len(self.train_sampler)\n",
    "\n",
    "    @lru_cache(maxsize=4)\n",
    "    def get_split(self, batch_size=50, num_workers=0):\n",
    "        logging.debug('Initializing train-validation-test dataloaders')\n",
    "        self.train_loader = self.get_train_loader(batch_size=batch_size, num_workers=num_workers)\n",
    "        self.val_loader = self.get_validation_loader(batch_size=batch_size, num_workers=num_workers)\n",
    "        self.test_loader = self.get_test_loader(batch_size=batch_size, num_workers=num_workers)\n",
    "        return self.train_loader, self.val_loader, self.test_loader\n",
    "\n",
    "    @lru_cache(maxsize=4)\n",
    "    def get_train_loader(self, batch_size=50, num_workers=0):\n",
    "        logging.debug('Initializing train dataloader')\n",
    "        self.train_loader = DataLoader(self.dataset, batch_size=batch_size, sampler=self.train_sampler, shuffle=False, num_workers=num_workers)\n",
    "        return self.train_loader\n",
    "\n",
    "    @lru_cache(maxsize=4)\n",
    "    def get_validation_loader(self, batch_size=50, num_workers=0):\n",
    "        logging.debug('Initializing validation dataloader')\n",
    "        self.val_loader = DataLoader(self.dataset, batch_size=batch_size, sampler=self.val_sampler, shuffle=False, num_workers=num_workers)\n",
    "        return self.val_loader\n",
    "\n",
    "    @lru_cache(maxsize=4)\n",
    "    def get_test_loader(self, batch_size=50, num_workers=0):\n",
    "        logging.debug('Initializing test dataloader')\n",
    "        self.test_loader = DataLoader(self.dataset, batch_size=batch_size, sampler=self.test_sampler, shuffle=False, num_workers=num_workers)\n",
    "        return self.test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2             3         4         5         6         7    \\\n",
      "0      2.3  0.2    1  1.507010e-26  0.012809  0.025618  0.038426  0.051234   \n",
      "1      2.4  0.2    1 -1.908640e-26  0.012808  0.025616  0.038423  0.051230   \n",
      "2      2.5  0.2    1  1.076793e-27  0.012807  0.025614  0.038421  0.051226   \n",
      "3      2.6  0.2    1 -2.257969e-27  0.012806  0.025613  0.038418  0.051223   \n",
      "4      2.7  0.2    1 -2.748220e-26  0.012806  0.025611  0.038416  0.051220   \n",
      "...    ...  ...  ...           ...       ...       ...       ...       ...   \n",
      "8215  35.3  2.1    1  3.612701e-25  0.019995  0.039982  0.059951  0.079893   \n",
      "8216  35.3  2.2    1  6.935291e-25  0.020404  0.040799  0.061176  0.081524   \n",
      "8217  35.3  2.3    1  5.082584e-25  0.020808  0.041606  0.062385  0.083133   \n",
      "8218  35.4  0.2    1  2.791266e-24  0.012794  0.025587  0.038381  0.051174   \n",
      "8219  35.4  0.3    1  1.262741e-23  0.012958  0.025916  0.038873  0.051830   \n",
      "\n",
      "           8         9    ...       155       156       157       158  \\\n",
      "0     0.064040  0.076845  ... -0.020753 -0.018140 -0.015530 -0.012924   \n",
      "1     0.064035  0.076839  ... -0.020919 -0.018292 -0.015667 -0.013043   \n",
      "2     0.064031  0.076834  ... -0.021070 -0.018431 -0.015791 -0.013152   \n",
      "3     0.064027  0.076830  ... -0.021208 -0.018558 -0.015905 -0.013251   \n",
      "4     0.064024  0.076826  ... -0.021334 -0.018674 -0.016009 -0.013342   \n",
      "...        ...       ...  ...       ...       ...       ...       ...   \n",
      "8215  0.099800  0.119665  ... -0.158858 -0.139152 -0.119391 -0.099580   \n",
      "8216  0.101834  0.122099  ... -0.162536 -0.142343 -0.122102 -0.101819   \n",
      "8217  0.103841  0.124502  ... -0.166052 -0.145392 -0.124692 -0.103957   \n",
      "8218  0.063966  0.076758  ... -0.024047 -0.021170 -0.018257 -0.015305   \n",
      "8219  0.064785  0.077739  ... -0.035654 -0.031385 -0.027061 -0.022684   \n",
      "\n",
      "           159       160       161       162  163  164  \n",
      "0    -0.010324 -0.007730 -0.005144 -0.002567  0.0    0  \n",
      "1    -0.010423 -0.007808 -0.005198 -0.002595  0.0    0  \n",
      "2    -0.010514 -0.007878 -0.005247 -0.002620  0.0    0  \n",
      "3    -0.010597 -0.007943 -0.005292 -0.002644  0.0    0  \n",
      "4    -0.010672 -0.008003 -0.005333 -0.002665  0.0    0  \n",
      "...        ...       ...       ...       ...  ...  ...  \n",
      "8215 -0.079727 -0.059837 -0.039915 -0.019968  0.0    0  \n",
      "8216 -0.081502 -0.061155 -0.040786 -0.020399  0.0    0  \n",
      "8217 -0.083196 -0.062413 -0.041616 -0.020809  0.0    0  \n",
      "8218 -0.012318 -0.009293 -0.006232 -0.003134  0.0    0  \n",
      "8219 -0.018253 -0.013769 -0.009232 -0.004642  0.0    0  \n",
      "\n",
      "[8220 rows x 165 columns]\n",
      "[[ 2.85920883e-27  2.43023526e-03  4.86041687e-03 ... -4.86974139e-04\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-3.62135000e-27  2.43014042e-03  4.86022896e-03 ... -4.92323335e-04\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 2.04311945e-28  2.43005695e-03  4.86006357e-03 ... -4.97193669e-04\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " ...\n",
      " [-7.29184672e-26  2.23067491e-03  4.46059410e-03 ... -2.17354536e-03\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 3.10750584e-26  2.22762573e-03  4.45444611e-03 ... -2.18897168e-03\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-1.75541993e-26  2.22546473e-03  4.45007590e-03 ... -2.20069627e-03\n",
      "   0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "data_matrix = df = pd.DataFrame()\n",
    "\n",
    "data_matrix = pd.read_csv(\"Data_folder/Data.csv\", header= None)\n",
    "\n",
    "print(data_matrix)\n",
    "\n",
    "\n",
    "# Make the droplet dataset class based on data_matrix\n",
    "class Droplet_data_set(Dataset):\n",
    "    def __init__(self):\n",
    "        x = data_matrix.iloc[0:8191,3:].values\n",
    "        y = data_matrix.iloc[0:8191,0].values\n",
    "        \n",
    "        # Add normalization for x\n",
    "        x = preprocessing.normalize(x)\n",
    "        print(x)\n",
    "\n",
    "        self.x_train=torch.tensor(x,dtype=torch.float32)\n",
    "        self.y_train=torch.tensor(y,dtype=torch.float32)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_train[idx],self.y_train[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "         return len(self.y_train)\n",
    "        \n",
    "my_data_set = Droplet_data_set()\n",
    "\n",
    "# Split the single dataset into 3 datasets for training, test and validation.\n",
    "split = DataSplit(my_data_set, shuffle=True)\n",
    "train_loader, val_loader, test_loader = split.get_split(batch_size=64, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deside to apply host or device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the functions we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_cal_per_epoch(loss_list, model, loader):\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        loss_epoch = 0\n",
    "        for t, (x, y) in enumerate(loader):\n",
    "            x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.float32)\n",
    "            scores = model(x)\n",
    "            loss = F.mse_loss(scores, y)\n",
    "            loss_epoch += loss\n",
    "        loss_list.append(loss_epoch/t)\n",
    "\n",
    "def train(model, optimizer, epochs=1):\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for _, (x, y) in enumerate(train_loader):\n",
    "            x = x.reshape(len(x), 1, 1, -1)     # reshape to 4D data for formal input of model\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.float32)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.mse_loss(scores, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        loss_cal_per_epoch(loss_train, model, train_loader)\n",
    "        loss_cal_per_epoch(loss_val, model, val_loader)\n",
    "        print('epoch %d: train_loss = %.4f, val_loss = %.4f' % (e+1, loss_train[e], loss_val[e]))\n",
    "    \n",
    "    x = range(1, epochs+1)\n",
    "    plt.plot(x, loss_train, 'b-', label=\"training loss\")\n",
    "    plt.plot(x, loss_val, 'r--', label=\"validation loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"MSE Loss\")\n",
    "    plt.title(\"Train/Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def prediction(model, x):   # only a batch\n",
    "    model = model.to(device=device)\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        x = x.to(device=device, dtype=torch.float32)\n",
    "        score = torch.Tensor.cpu(model(x))\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train PhysicsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: train_loss = 384.3715, val_loss = 409.3900\n",
      "epoch 2: train_loss = 321.1073, val_loss = 336.8753\n",
      "epoch 3: train_loss = 243.2097, val_loss = 262.8041\n",
      "epoch 4: train_loss = 172.5598, val_loss = 185.0055\n",
      "epoch 5: train_loss = 131.0035, val_loss = 142.0968\n",
      "epoch 6: train_loss = 112.7700, val_loss = 124.4006\n",
      "epoch 7: train_loss = 105.5634, val_loss = 113.0780\n",
      "epoch 8: train_loss = 102.0210, val_loss = 109.6416\n",
      "epoch 9: train_loss = 101.1859, val_loss = 105.7625\n",
      "epoch 10: train_loss = 97.4724, val_loss = 100.4996\n",
      "epoch 11: train_loss = 97.3380, val_loss = 101.1969\n",
      "epoch 12: train_loss = 92.5065, val_loss = 97.4765\n",
      "epoch 13: train_loss = 93.4533, val_loss = 99.6852\n",
      "epoch 14: train_loss = 92.2551, val_loss = 95.6799\n",
      "epoch 15: train_loss = 90.3556, val_loss = 97.1709\n",
      "epoch 16: train_loss = 89.3725, val_loss = 95.9587\n",
      "epoch 17: train_loss = 90.6099, val_loss = 95.5221\n",
      "epoch 18: train_loss = 88.9788, val_loss = 93.9893\n",
      "epoch 19: train_loss = 87.9597, val_loss = 95.7988\n",
      "epoch 20: train_loss = 86.0381, val_loss = 90.5111\n",
      "epoch 21: train_loss = 85.9437, val_loss = 91.0463\n",
      "epoch 22: train_loss = 85.3411, val_loss = 88.9665\n",
      "epoch 23: train_loss = 84.1331, val_loss = 87.9960\n",
      "epoch 24: train_loss = 84.5304, val_loss = 92.0762\n",
      "epoch 25: train_loss = 85.3583, val_loss = 90.4599\n",
      "epoch 26: train_loss = 83.6983, val_loss = 86.6147\n",
      "epoch 27: train_loss = 83.5680, val_loss = 88.9892\n",
      "epoch 28: train_loss = 82.8016, val_loss = 90.8303\n",
      "epoch 29: train_loss = 82.6620, val_loss = 87.0173\n",
      "epoch 30: train_loss = 81.3663, val_loss = 86.0138\n",
      "epoch 31: train_loss = 82.0739, val_loss = 88.1157\n",
      "epoch 32: train_loss = 81.6351, val_loss = 87.0706\n",
      "epoch 33: train_loss = 82.0784, val_loss = 87.8957\n",
      "epoch 34: train_loss = 82.2503, val_loss = 88.9121\n",
      "epoch 35: train_loss = 81.7852, val_loss = 86.9840\n",
      "epoch 36: train_loss = 81.6279, val_loss = 83.8010\n",
      "epoch 37: train_loss = 80.5782, val_loss = 87.0471\n",
      "epoch 38: train_loss = 80.6210, val_loss = 86.6660\n",
      "epoch 39: train_loss = 79.8002, val_loss = 84.1458\n",
      "epoch 40: train_loss = 80.2674, val_loss = 85.4408\n",
      "epoch 41: train_loss = 80.1409, val_loss = 88.0059\n",
      "epoch 42: train_loss = 80.1515, val_loss = 90.1781\n",
      "epoch 43: train_loss = 79.8354, val_loss = 84.3518\n",
      "epoch 44: train_loss = 79.9143, val_loss = 86.8261\n",
      "epoch 45: train_loss = 79.4577, val_loss = 85.3599\n",
      "epoch 46: train_loss = 78.9364, val_loss = 84.2632\n",
      "epoch 47: train_loss = 79.4885, val_loss = 86.2052\n",
      "epoch 48: train_loss = 79.2096, val_loss = 85.4132\n",
      "epoch 49: train_loss = 79.3117, val_loss = 83.9520\n",
      "epoch 50: train_loss = 79.4386, val_loss = 84.6880\n",
      "epoch 51: train_loss = 78.3560, val_loss = 84.9935\n",
      "epoch 52: train_loss = 78.6156, val_loss = 80.9953\n",
      "epoch 53: train_loss = 78.3493, val_loss = 84.9938\n",
      "epoch 54: train_loss = 78.8747, val_loss = 83.4397\n",
      "epoch 55: train_loss = 78.6577, val_loss = 83.7141\n",
      "epoch 56: train_loss = 79.1151, val_loss = 84.2783\n",
      "epoch 57: train_loss = 78.4931, val_loss = 83.2272\n",
      "epoch 58: train_loss = 78.7009, val_loss = 82.0430\n",
      "epoch 59: train_loss = 78.2710, val_loss = 85.7652\n",
      "epoch 60: train_loss = 78.7344, val_loss = 85.3830\n",
      "epoch 61: train_loss = 77.9080, val_loss = 83.2840\n",
      "epoch 62: train_loss = 78.8901, val_loss = 83.1381\n",
      "epoch 63: train_loss = 78.7253, val_loss = 85.7753\n",
      "epoch 64: train_loss = 77.7493, val_loss = 82.7814\n",
      "epoch 65: train_loss = 78.1590, val_loss = 83.3102\n",
      "epoch 66: train_loss = 78.3146, val_loss = 84.0551\n",
      "epoch 67: train_loss = 77.6717, val_loss = 84.3482\n",
      "epoch 68: train_loss = 78.2599, val_loss = 86.1868\n",
      "epoch 69: train_loss = 77.8388, val_loss = 81.9071\n",
      "epoch 70: train_loss = 77.8260, val_loss = 82.9342\n",
      "epoch 71: train_loss = 77.7238, val_loss = 83.5990\n",
      "epoch 72: train_loss = 77.9054, val_loss = 82.3301\n",
      "epoch 73: train_loss = 77.8888, val_loss = 83.5317\n",
      "epoch 74: train_loss = 77.9820, val_loss = 86.7004\n",
      "epoch 75: train_loss = 77.9809, val_loss = 85.7509\n",
      "epoch 76: train_loss = 77.4388, val_loss = 84.1874\n",
      "epoch 77: train_loss = 77.1163, val_loss = 82.5485\n",
      "epoch 78: train_loss = 78.1924, val_loss = 83.3879\n",
      "epoch 79: train_loss = 78.3230, val_loss = 82.9519\n",
      "epoch 80: train_loss = 77.5880, val_loss = 81.5026\n",
      "epoch 81: train_loss = 77.4005, val_loss = 86.2395\n",
      "epoch 82: train_loss = 78.3265, val_loss = 83.0972\n",
      "epoch 83: train_loss = 77.5439, val_loss = 83.9617\n",
      "epoch 84: train_loss = 77.9490, val_loss = 85.0365\n",
      "epoch 85: train_loss = 77.6996, val_loss = 83.5482\n",
      "epoch 86: train_loss = 78.0277, val_loss = 85.3212\n",
      "epoch 87: train_loss = 77.6363, val_loss = 81.6902\n",
      "epoch 88: train_loss = 77.4081, val_loss = 83.9298\n",
      "epoch 89: train_loss = 77.5632, val_loss = 81.8499\n",
      "epoch 90: train_loss = 77.6695, val_loss = 83.4546\n",
      "epoch 91: train_loss = 77.4717, val_loss = 81.7838\n",
      "epoch 92: train_loss = 77.5405, val_loss = 81.7231\n",
      "epoch 93: train_loss = 77.2532, val_loss = 82.9762\n",
      "epoch 94: train_loss = 77.5583, val_loss = 83.5949\n",
      "epoch 95: train_loss = 77.1481, val_loss = 82.7013\n",
      "epoch 96: train_loss = 77.7897, val_loss = 83.8329\n",
      "epoch 97: train_loss = 78.1037, val_loss = 84.0180\n",
      "epoch 98: train_loss = 77.1646, val_loss = 82.5075\n",
      "epoch 99: train_loss = 78.3332, val_loss = 83.3004\n",
      "epoch 100: train_loss = 77.1224, val_loss = 83.0126\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "in_channel = 162\n",
    "node_1 = 256\n",
    "node_2 = 256\n",
    "node_3 = 128\n",
    "node_4 = 64\n",
    "out_channel = 1\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model_physics = PhysicsNet(in_channel, node_1, node_2, node_3, node_4, out_channel)\n",
    "optimizer = optim.Adam(model_physics.parameters(), lr=learning_rate)\n",
    "epoch = 100\n",
    "\n",
    "train(model_physics, optimizer, epoch)\n",
    "PATH_CAL = os.path.join(os.getcwd(), \"model_cal\")\n",
    "torch.save(model_physics, PATH_CAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truths = tensor([33.7000, 18.4000,  7.4000, 28.6000, 27.9000, 13.3000,  9.7000, 34.3000])\n",
      "Prediction    = tensor([[17.8167, 18.2857, 18.2144, 17.6725, 17.6725, 18.1907, 18.1782, 18.0335]])\n"
     ]
    }
   ],
   "source": [
    "model_trained = torch.load(PATH_CAL)\n",
    "\n",
    "examples = enumerate(test_loader)\n",
    "_, (x_test_example, y_test_example) = next(examples)\n",
    "\n",
    "score_example = prediction(model_trained, x_test_example)\n",
    "\n",
    "# Print only 8 data samples for comparison\n",
    "print(\"Ground Truths =\", y_test_example[:8])\n",
    "print(\"Prediction    =\", score_example[:8].reshape(1, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64def4006c78149665c79cf5850ee76c9e416630a0d9e75e41ff194dcaf5fb2b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
