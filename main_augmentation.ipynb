{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For spline (two-model) method training only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages and self-defined classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F  # useful stateless functions\n",
    "# Test/Train data split\n",
    "from functools import lru_cache\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import logging\n",
    "# sklearn\n",
    "from sklearn import preprocessing\n",
    "# os\n",
    "import os\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# random\n",
    "import random\n",
    "# math\n",
    "import math\n",
    "import scipy.interpolate\n",
    "# self-defined model\n",
    "from model_pic import *\n",
    "from model_cal import *\n",
    "from model_one import *\n",
    "import pandas as pd\n",
    "\n",
    "#PictureNet\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augamented dataset loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSplit:\n",
    "\n",
    "    def __init__(self, dataset, test_train_split=0.9, val_train_split=0.1, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "\n",
    "        dataset_size = len(dataset)\n",
    "        self.indices = list(range(dataset_size))\n",
    "        test_split = int(np.floor(test_train_split * dataset_size))\n",
    "\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "        train_indices, self.test_indices = self.indices[:test_split], self.indices[test_split:]\n",
    "        train_size = len(train_indices)\n",
    "        validation_split = int(np.floor((1 - val_train_split) * train_size))\n",
    "\n",
    "        self.train_indices, self.val_indices = train_indices[:validation_split], train_indices[validation_split:]\n",
    "\n",
    "        self.train_sampler = SubsetRandomSampler(self.train_indices)\n",
    "        self.val_sampler = SubsetRandomSampler(self.val_indices)\n",
    "        self.test_sampler = SubsetRandomSampler(self.test_indices)\n",
    "    \n",
    "    def get_train_split_point(self):\n",
    "        return len(self.train_sampler) + len(self.val_indices)\n",
    "\n",
    "    def get_validation_split_point(self):\n",
    "        return len(self.train_sampler)\n",
    "\n",
    "    @lru_cache(maxsize=4)\n",
    "    def get_split(self, batch_size=64, num_workers=0):\n",
    "        logging.debug('Initializing train-validation-test dataloaders')\n",
    "        self.train_loader = self.get_train_loader(batch_size=batch_size, num_workers=num_workers)\n",
    "        self.val_loader = self.get_validation_loader(batch_size=batch_size, num_workers=num_workers)\n",
    "        self.test_loader = self.get_test_loader(batch_size=batch_size, num_workers=num_workers)\n",
    "        return self.train_loader, self.val_loader, self.test_loader\n",
    "\n",
    "    @lru_cache(maxsize=4)\n",
    "    def get_train_loader(self, batch_size=64, num_workers=0):\n",
    "        logging.debug('Initializing train dataloader')\n",
    "        self.train_loader = DataLoader(self.dataset, batch_size=batch_size, sampler=self.train_sampler, shuffle=False, num_workers=num_workers)\n",
    "        return self.train_loader\n",
    "\n",
    "    @lru_cache(maxsize=4)\n",
    "    def get_validation_loader(self, batch_size=64, num_workers=0):\n",
    "        logging.debug('Initializing validation dataloader')\n",
    "        self.val_loader = DataLoader(self.dataset, batch_size=batch_size, sampler=self.val_sampler, shuffle=False, num_workers=num_workers)\n",
    "        return self.val_loader\n",
    "\n",
    "    @lru_cache(maxsize=4)\n",
    "    def get_test_loader(self, batch_size=64, num_workers=0):\n",
    "        logging.debug('Initializing test dataloader')\n",
    "        self.test_loader = DataLoader(self.dataset, batch_size=batch_size, sampler=self.test_sampler, shuffle=False, num_workers=num_workers)\n",
    "        return self.test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data for PhysicsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1          2         3         4         5         6   \\\n",
      "0      15.1   5.10061  14.150364  0.641996  0.560755 -0.204328 -0.058190   \n",
      "1      15.1   5.20122  13.846032  0.643660  0.560057 -0.206831 -0.056986   \n",
      "2      15.1   5.30183  13.542532  0.645277  0.559330 -0.209271 -0.055732   \n",
      "3      15.1   5.40244  13.239690  0.646846  0.558572 -0.211646 -0.054425   \n",
      "4      15.1   5.50305  12.937316  0.648367  0.557781 -0.213957 -0.053062   \n",
      "...     ...       ...        ...       ...       ...       ...       ...   \n",
      "24742  86.1  25.28098  68.539411  0.889489  0.557742 -0.559551 -0.052669   \n",
      "24743  86.1  25.81469  67.593048  0.892798  0.556636 -0.564524 -0.050794   \n",
      "24744  86.1  26.34840  66.662881  0.896025  0.555496 -0.569388 -0.048861   \n",
      "24745  86.1  26.88211  65.747951  0.899170  0.554318 -0.574146 -0.046868   \n",
      "24746  86.1  27.41582  64.847338  0.902236  0.553103 -0.578799 -0.044812   \n",
      "\n",
      "             7         8         9   ...        15        16        17  \\\n",
      "0      0.073569 -0.004100 -0.013163  ...  1.121736  0.132903 -0.177839   \n",
      "1      0.074633 -0.004738 -0.013435  ...  1.137861  0.133661 -0.180555   \n",
      "2      0.075681 -0.005403 -0.013707  ...  1.154047  0.134405 -0.183274   \n",
      "3      0.076712 -0.006095 -0.013980  ...  1.170311  0.135135 -0.185999   \n",
      "4      0.077728 -0.006815 -0.014253  ...  1.186667  0.135851 -0.188732   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "24742  0.199905 -0.007579 -0.034699  ...  2.243991  0.203612 -0.379882   \n",
      "24743  0.202004 -0.008527 -0.035211  ...  2.269844  0.205086 -0.383941   \n",
      "24744  0.204077 -0.009501 -0.035725  ...  2.295674  0.206566 -0.387971   \n",
      "24745  0.206125 -0.010503 -0.036240  ...  2.321496  0.208054 -0.391974   \n",
      "24746  0.208150 -0.011534 -0.036757  ...  2.347329  0.209550 -0.395954   \n",
      "\n",
      "             18        19        20        21        22        23        24  \n",
      "0     -0.036451  0.026592  0.000080 -0.004749  0.001136  0.000689 -0.000318  \n",
      "1     -0.036399  0.027049 -0.000124 -0.004824  0.001213  0.000696 -0.000337  \n",
      "2     -0.036334  0.027502 -0.000335 -0.004896  0.001293  0.000702 -0.000357  \n",
      "3     -0.036256  0.027950 -0.000554 -0.004965  0.001375  0.000707 -0.000377  \n",
      "4     -0.036166  0.028394 -0.000780 -0.005030  0.001460  0.000711 -0.000399  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "24742 -0.049489  0.067531 -0.004278 -0.013421  0.002814  0.002137 -0.000635  \n",
      "24743 -0.049304  0.068179 -0.004714 -0.013574  0.002956  0.002166 -0.000664  \n",
      "24744 -0.049110  0.068811 -0.005159 -0.013724  0.003101  0.002194 -0.000693  \n",
      "24745 -0.048905  0.069428 -0.005614 -0.013869  0.003250  0.002221 -0.000723  \n",
      "24746 -0.048690  0.070031 -0.006079 -0.014011  0.003402  0.002249 -0.000754  \n",
      "\n",
      "[24747 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "data_matrix_augmentation = pd.read_csv(\"pendant_drop/Data_Hole/Spline_Hole.csv\", header= None)\n",
    "print(data_matrix_augmentation)\n",
    "\n",
    "# Make the droplet dataset class based on data_matrix\n",
    "class Droplet_data_set(Dataset):\n",
    "    def __init__(self,dataInput):\n",
    "        x = dataInput.iloc[0:,3:].values\n",
    "        y = dataInput.iloc[0:,0:2].values\n",
    "        # x = np.random.normal(x,0.01)\n",
    "        y0 = dataInput.iloc[:,0].values\n",
    "        y1 = dataInput.iloc[:,1].values\n",
    "        \n",
    "        # Plot surface tension histogram\n",
    "        n, bins, patches = plt.hist(x=y0, bins='auto', color='#0504aa',\n",
    "                                    alpha=0.7, rwidth=0.85)\n",
    "        plt.grid(axis='y', alpha=0.75)\n",
    "        plt.xlabel('Surface Tension[mN/m]')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Occurence of data per Surface Tension')\\\n",
    "\n",
    "        # Plot volume histogram\n",
    "        # n, bins, patches = plt.hist(x=y1, bins='auto', color='#0504aa',\n",
    "        #                             alpha=0.7, rwidth=0.85)\n",
    "        # plt.grid(axis='y', alpha=0.75)\n",
    "        # plt.xlabel('Volume[mm^3]')\n",
    "        # plt.ylabel('Frequency')\n",
    "        # plt.title('Occurence of data per Volume')\n",
    "\n",
    "        self.x_train = torch.tensor(x,dtype=torch.float32)\n",
    "        self.y_train = torch.tensor(y,dtype=torch.float32)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_train[idx],self.y_train[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "         return len(self.y_train)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data for PictureNet\n",
    "Read image from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = []\n",
    "data_matrix_augmentation = pd.read_csv(\"pendant_drop/Data_Hole/Spline_Hole.csv\", header= None)\n",
    "data_image_augmentation = data_matrix_augmentation\n",
    "\n",
    "for img_name in data_image_augmentation.iloc[0:,3:].index + 1:      # modify the number depends on size of dataset\n",
    "    # defining the image path\n",
    "    image_path = 'pendant_drop/Data_Hole/' + str(img_name) + '.png'      # modify the path depends on which dataset\n",
    "    # reading the image\n",
    "    img = imread(image_path, as_gray=True)\n",
    "    img = img[4:-4, 4:-4]  #crop \n",
    "    # normalizing the pixel values\n",
    "    img /= 255.0\n",
    "    # converting the type of pixel to float 32\n",
    "    img = img.astype('float32')\n",
    "    # appending the image into the list\n",
    "    train_img.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a single image for viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image = 9392\n",
      "Picture size = (82, 77)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1de39c6d100>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand = random.randint(1, 27386)\n",
    "print(\"Current image =\", rand)\n",
    "print(\"Picture size =\", train_img[rand].shape)\n",
    "plt.imshow(train_img[rand], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and transfer the data from list to torch format\n",
    "def split_n_transfer(x, y):\n",
    "    # Points data split\n",
    "    train_x_pic, rem_x_pic, train_y_pic, rem_y_pic = train_test_split(x, y, test_size = 0.2)    # default shuffle = True\n",
    "    val_x_pic, test_x_pic, val_y_pic, test_y_pic = train_test_split(rem_x_pic, rem_y_pic, test_size = 0.5)\n",
    "\n",
    "    # converting the train images of points and targets into torch format\n",
    "    train_x_pic = train_x_pic.reshape(len(train_x_pic), 1, 82, 77)\n",
    "    train_x_pic = torch.from_numpy(train_x_pic)\n",
    "    train_y_pic = torch.from_numpy(train_y_pic)\n",
    "\n",
    "    # converting the val images and target points into torch format\n",
    "    val_x_pic = val_x_pic.reshape(len(val_x_pic), 1, 82, 77)\n",
    "    val_x_pic = torch.from_numpy(val_x_pic)\n",
    "    val_y_pic = torch.from_numpy(val_y_pic)\n",
    "    # print(val_x_pic.shape, val_y_pic.shape)\n",
    "\n",
    "    # converting the test images and targets into torch format for points\n",
    "    test_x_pic = test_x_pic.reshape(len(test_x_pic), 1, 82, 77)\n",
    "    test_x_pic  = torch.from_numpy(test_x_pic)\n",
    "    test_y_pic = torch.from_numpy(test_y_pic)\n",
    "    # print(test_x_pic.shape, test_y_pic.shape)\n",
    "    \n",
    "    return train_x_pic, train_y_pic, val_x_pic, val_y_pic, test_x_pic, test_y_pic\n",
    "\n",
    "# converting the dataset into mini-batch dataset (input 4D -> 5D and 2D -> 3D)\n",
    "def batch_transform(dataset, batch_size=512):\n",
    "    batch = []\n",
    "    batch_num = math.ceil(len(dataset)/batch_size)\n",
    "    for i in range(batch_num):\n",
    "        if len(dataset) == 4:\n",
    "            if i < batch_num-1:\n",
    "                batch.append(dataset[i*batch_size:(i+1)*batch_size, :, :, :])\n",
    "            else:\n",
    "                batch.append(dataset[i*batch_size:, :, :, :])\n",
    "        else:\n",
    "            if i < batch_num-1:\n",
    "                batch.append(dataset[i*batch_size:(i+1)*batch_size, :])\n",
    "            else:\n",
    "                batch.append(dataset[i*batch_size:, :])\n",
    "    return batch\n",
    "\n",
    "# converting all raw datasets into batch datasets in the same time\n",
    "def batch_all(train_x, train_y, val_x, val_y, test_x, test_y):\n",
    "    train_x_pic = batch_transform(train_x)\n",
    "    train_y_pic = batch_transform(train_y)\n",
    "    val_x_pic = batch_transform(val_x)\n",
    "    val_y_pic = batch_transform(val_y)\n",
    "    test_x_pic = batch_transform(test_x)\n",
    "    test_y_pic = batch_transform(test_y)\n",
    "    return train_x_pic, train_y_pic, val_x_pic, val_y_pic, test_x_pic, test_y_pic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and splite the dataset for edge point model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 39 5 5 5 5\n"
     ]
    }
   ],
   "source": [
    "# converting the list to numpy array\n",
    "train_x_pic = np.array(train_img)\n",
    "train_y_pic_augmentation = data_image_augmentation.iloc[0:,3:].values\n",
    "\n",
    "train_x_pic_augmentation, train_y_pic_augmentation, val_x_pic_augmentation, val_y_pic_augmentation, test_x_pic_augmentation, test_y_pic_augmentation = \\\n",
    "    split_n_transfer(train_x_pic, train_y_pic_augmentation)\n",
    "\n",
    "train_x_pic_augmentation, train_y_pic_augmentation, val_x_pic_augmentation, val_y_pic_augmentation, test_x_pic_augmentation, test_y_pic_augmentation = \\\n",
    "    batch_all(train_x_pic_augmentation, train_y_pic_augmentation, val_x_pic_augmentation, val_y_pic_augmentation, test_x_pic_augmentation, test_y_pic_augmentation)\n",
    "    \n",
    "print(len(train_x_pic_augmentation), len(train_y_pic_augmentation), len(val_x_pic_augmentation), \\\n",
    "    len(val_y_pic_augmentation), len(test_x_pic_augmentation), len(test_y_pic_augmentation))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64def4006c78149665c79cf5850ee76c9e416630a0d9e75e41ff194dcaf5fb2b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
