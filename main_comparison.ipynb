{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load unseen test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F  # useful stateless functions\n",
    "# Test/Train data split\n",
    "from functools import lru_cache\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import logging\n",
    "# sklearn\n",
    "from sklearn import preprocessing\n",
    "# os\n",
    "import os\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# random\n",
    "import random\n",
    "# math\n",
    "import math\n",
    "import scipy.interpolate\n",
    "import pandas as pd\n",
    "# self-defined model\n",
    "from model_pic import *\n",
    "from model_cal import *\n",
    "from model_one import *\n",
    "\n",
    "\n",
    "#PictureNet\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read image from files </br>\n",
    "<font color=red>\n",
    "Need to change the dataset to unseen test\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = []\n",
    "data_matrix_points = pd.read_csv(\"Data_uniform/Edge_points.csv\", header= None)\n",
    "data_matrix_spline = pd.read_csv(\"Data_uniform/Spline.csv\", header= None)\n",
    "data_image_points = data_matrix_points  \n",
    "data_image_spline = data_matrix_spline\n",
    "\n",
    "for img_name in data_image_points.iloc[0:,3:].index + 1:      # modify the number depends on size of dataset\n",
    "    # defining the image path\n",
    "    image_path = 'Data_uniform/' + str(img_name) + '.png'      # modify the path depends on which dataset\n",
    "    # reading the image\n",
    "    img = imread(image_path, as_gray=True)\n",
    "    img = img[4:-4, 4:-4]  #crop \n",
    "    # normalizing the pixel values\n",
    "    img /= 255.0\n",
    "    # converting the type of pixel to float 32\n",
    "    img = img.astype('float32')\n",
    "    # appending the image into the list\n",
    "    train_img.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a single image for viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = random.randint(1, 27000)\n",
    "print(\"Current image =\", rand)\n",
    "print(\"Picture size =\", train_img[rand].shape)\n",
    "plt.imshow(train_img[rand], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and transfer the data from list to torch format\n",
    "def split_n_transfer(x, y):\n",
    "    # Points data split\n",
    "    train_x_pic, rem_x_pic, train_y_pic, rem_y_pic = train_test_split(x, y, test_size = 0.2)    # default shuffle = True\n",
    "    val_x_pic, test_x_pic, val_y_pic, test_y_pic = train_test_split(rem_x_pic, rem_y_pic, test_size = 0.5)\n",
    "\n",
    "    # converting the train images of points and targets into torch format\n",
    "    train_x_pic = train_x_pic.reshape(len(train_x_pic), 1, 82, 77)\n",
    "    train_x_pic = torch.from_numpy(train_x_pic)\n",
    "    train_y_pic = torch.from_numpy(train_y_pic)\n",
    "\n",
    "    # converting the val images and target points into torch format\n",
    "    val_x_pic = val_x_pic.reshape(len(val_x_pic), 1, 82, 77)\n",
    "    val_x_pic = torch.from_numpy(val_x_pic)\n",
    "    val_y_pic = torch.from_numpy(val_y_pic)\n",
    "    # print(val_x_pic.shape, val_y_pic.shape)\n",
    "\n",
    "    # converting the test images and targets into torch format for points\n",
    "    test_x_pic = test_x_pic.reshape(len(test_x_pic), 1, 82, 77)\n",
    "    test_x_pic  = torch.from_numpy(test_x_pic)\n",
    "    test_y_pic = torch.from_numpy(test_y_pic)\n",
    "    # print(test_x_pic.shape, test_y_pic.shape)\n",
    "    \n",
    "    return train_x_pic, train_y_pic, val_x_pic, val_y_pic, test_x_pic, test_y_pic\n",
    "\n",
    "# converting the dataset into mini-batch dataset (input 4D -> 5D and 2D -> 3D)\n",
    "def batch_transform(dataset, batch_size=512):\n",
    "    batch = []\n",
    "    batch_num = math.ceil(len(dataset)/batch_size)\n",
    "    for i in range(batch_num):\n",
    "        if len(dataset) == 4:\n",
    "            if i < batch_num-1:\n",
    "                batch.append(dataset[i*batch_size:(i+1)*batch_size, :, :, :])\n",
    "            else:\n",
    "                batch.append(dataset[i*batch_size:, :, :, :])\n",
    "        else:\n",
    "            if i < batch_num-1:\n",
    "                batch.append(dataset[i*batch_size:(i+1)*batch_size, :])\n",
    "            else:\n",
    "                batch.append(dataset[i*batch_size:, :])\n",
    "    return batch\n",
    "\n",
    "# converting all raw datasets into batch datasets in the same time\n",
    "def batch_all(train_x, train_y, val_x, val_y, test_x, test_y):\n",
    "    train_x_pic = batch_transform(train_x)\n",
    "    train_y_pic = batch_transform(train_y)\n",
    "    val_x_pic = batch_transform(val_x)\n",
    "    val_y_pic = batch_transform(val_y)\n",
    "    test_x_pic = batch_transform(test_x)\n",
    "    test_y_pic = batch_transform(test_y)\n",
    "    return train_x_pic, train_y_pic, val_x_pic, val_y_pic, test_x_pic, test_y_pic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Model method v.s. Two-Model method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_ONE = os.path.join(os.getcwd(), \"model_one.pt\")\n",
    "\n",
    "model_physics_trained_points = torch.load(PATH_ONE)\n",
    "\n",
    "examples = enumerate(test_loader_points)\n",
    "_, (x_test_points, y_test_points) = next(examples)\n",
    "\n",
    "score_example_points = prediction(model_physics_trained_points, x_test_points)\n",
    "\n",
    "# Print only 8 data samples for comparison\n",
    "print(\"Ground Truths     =\", y_test_points[:8])\n",
    "print(\"Prediction Points =\", score_example_points[:8].reshape(8, 2))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64def4006c78149665c79cf5850ee76c9e416630a0d9e75e41ff194dcaf5fb2b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
